MODEL:
  simple_cfg: '../simple-baseline-pytorch/experiments/pt17/res50-coco-256x192_d256x3_adam_lr1e-3.yaml'
  simple_model: '/home/zhangxt/disk/posetrack/simple-baseline-pytorch/output-pt17-freeze/pt17/pose_resnet_50/res50-coco-256x192_d256x3_adam_lr1e-3/pt17-epoch-16-88.01324110762047'
ALG:
  FILTER_HUMAN_WHEN_DETECT: False
  _HUMAN_THRES: 0.5

  JOINT_PROP_WITH_FILTERED_HUMAN: False
  PROP_HUMAN_THRES: .5

  USE_COCO_IOU_IN_NMS: False
  UNIFY_NMS_THRES_1: .35
  UNIFY_NMS_THRES_2: .5

  ASSGIN_ID_TO_FILTERED_BOX: True
  ASSIGN_BOX_THRES: 0.8
  OUTPUT_JOINT_THRES: 0.5
  MATCHING_ALG: 0
TEST:
  USE_GT_PEOPLE_BOX: True
  FLIP_TEST: True
  USE_GT_JOINTS_TO_PROP: False
  USE_ALL_GT_JOINTS_TO_PROP: False
  GT_BOX_SCORE: .7
  FROM: 0
  TO: 50
#  ONLY_TEST:
#    - '03742'
#    - 14102_mpii
#    -  20880_mpii_relpath_5sec_testsub

  TASK: -2
  MODE: valid
DEBUG:
  VISUALIZE: False
  VIS_BOX: True
  VIS_HUMAN_THRES: 0.0

  SAVE_DETECTION_TENSOR: False
  SAVE_FLOW_TENSOR: False
  SAVE_DETECTION_S_EST: False
  SAVE_NMS_TENSOR: False
  NO_NMS: False
  USE_DETECTION_RESULT: False
  USE_FLOW_RESULT: False
  USE_DET_EST_RESULT: False
  load_joint_est_model: False
  load_human_det_model: False
PATH:
  _JOINTS_DIR: 'images_joint-track-88-withflip/'
  _IMAGES_OUT_DIR: 'images_out-track-88-withflip/'
  _JSON_SAVE_DIR: 'pred_json-track-88-withflip/'
  _UNIFIED_JSON_DIR: 'unifed_boxes-track-88-withflip/'
  UNI_BOX_FOR_TASK_3: 'unifed_boxes-commi-onlydet/valid_task_1_DETbox_allBox_tfIoU_nmsThres_0.35_0.50'
  PRED_JSON_FOR_TASK_3: 'pred_json-single-est/75.5-valid_res50_task_1_GTbox_allBox_Flip_noNMS/'
